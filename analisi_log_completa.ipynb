{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_py.run_log_parser import RunLogParser\n",
    "from file_py.csv_preprocessing_scaler_full import CsvPreprocessingScalerFull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CsvPreprocessingScalerFull.read_csv_file(\"file_csv/LogSplunk_12_06_Full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = CsvPreprocessingScalerFull.RawPreprocessing(df)\n",
    "\n",
    "df_Le = CsvPreprocessingScalerFull.LEPreprocessing(df)\n",
    "df_OH = CsvPreprocessingScalerFull.OhePreprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std_LE = CsvPreprocessingScalerFull.stdScaler(CsvPreprocessingScalerFull.LEPreprocessing(df))\n",
    "df_std_OH = CsvPreprocessingScalerFull.stdScaler(CsvPreprocessingScalerFull.OhePreprocessing(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'file_csv/attackLog_12_06.csv'\n",
    "result_df_Le = RunLogParser.process_attacks(file_path, CsvPreprocessingScalerFull.stdScaler(CsvPreprocessingScalerFull.LEPreprocessing(df)))\n",
    "result_df_OH = RunLogParser.process_attacks(file_path, CsvPreprocessingScalerFull.stdScaler(CsvPreprocessingScalerFull.OhePreprocessing(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphic Analysis of Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_py.plots import Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_Raw = RunLogParser.process_attacks(file_path, CsvPreprocessingScalerFull.RawPreprocessing(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_cake_attack(result_df_Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_top_10_mitre_id(result_df_Raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui si può notare come generalmente le __regole scattate più volte__ sono anche quelle che hanno effettivamente __risposto a più attachi__.  \n",
    "Tra le regole presenti nella prima tabella solo __T1003.002__ e __T1548__ NON si trovano nella seconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_value_counts_per_unique(result_df_Raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grazie a questo grafico invece possiamo giungere ad una serie di conclusioni.  \n",
    "Su __66__ regole diverse:  \n",
    "- quelle scattate in risposta ad ALMENO un attacco reale sono __44__.  \n",
    "Le __22__ regole che si sono attivate senza rispondere ad attacchi sono:  \n",
    "T1555.004, T1552.004, T1546.011, T1082, T1021.003, T1218, T1566.001, T1218.010, T1204.002, T1218.011, T1053.002, T1552.006, T1059.007, T1070.001, T1562.002, T1562.001, T1136.001, T1133, T1059.005, T1615, T1560.001, T1197\n",
    "\n",
    "- delle 44 in risposta ad attacchi reali:  \n",
    "    - __20__ si sono attivate più volte per __non-attacchi__ rispetto che per gli attacchi\n",
    "    - __8__ si sono attivate lo __stesso numero__ di volte per attacchi e non-attacchi\n",
    "    - __16__ si sono attivate più volte in risposta ad __attacchi__ rispetto che a non-attacchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_distributions(result_df_Raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo grafico invece notiamo che la distribuzione tra attacchi e non-attacchi:\n",
    "- secondo il \"__severity_id__\" rimane __stabile__;\n",
    "- secondo il \"__tag__\" rimane stabile ad eccezione di \"__attack communicate malware network__\" che in rapporto agli altri registra un numero considerevole di non-attacchi in confronto agli attacchi;\n",
    "- secondo l' \"__EventType__\" rimane stabile ad eccezione del \"__4__\" che in rapporto agli altri registra un numero considerevole di non-attacchi in confronto agli attacchi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_py.correlation_matrix_plots import CorrelationMatrixPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorrelationMatrixPlots.plot_correlation_matrix(result_df_Le, 'Correlation Matrix (Label Encoding)')\n",
    "CorrelationMatrixPlots.plot_correlation_matrix_big(result_df_OH, 'Correlation Matrix (OneHot Encoding)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_py.preprocessing_train_test_split import PreprocessingTrainTestSplit\n",
    "from file_py.initial_training import InitialTraining\n",
    "from file_py.hyperparameter_tuning import HyperparameterTuning\n",
    "from file_py.advanced_models import AdvancedModels\n",
    "from file_py.deep_learning_model import DeepLearningModel\n",
    "from file_py.model_evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_OH, X_test_OH, y_train_OH, y_test_OH = PreprocessingTrainTestSplit.split_data(result_df_OH, \"corrisponde_ad_attacco\")\n",
    "\n",
    "# Initial model training and evaluation\n",
    "InitialTraining.train_and_evaluate_initial_models(X_train_OH, y_train_OH, X_test_OH, y_test_OH)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best_models_OH = HyperparameterTuning.tune_hyperparameters(X_train_OH, y_train_OH)\n",
    "\n",
    "# Evaluate best models on test set\n",
    "evaluator_OH = ModelEvaluator(best_models_OH)\n",
    "evaluation_results_OH = evaluator_OH.evaluate_models(X_test_OH, y_test_OH)\n",
    "\n",
    "# Train XGBoost model\n",
    "AdvancedModels.train_xgboost(X_train_OH, y_train_OH, X_test_OH, y_test_OH)\n",
    "\n",
    "# Train deep learning model\n",
    "DeepLearningModel.train_deep_learning_model(X_train_OH, y_train_OH, X_test_OH, y_test_OH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_Le, X_test_Le, y_train_Le, y_test_Le = PreprocessingTrainTestSplit.split_data(result_df_Le, \"corrisponde_ad_attacco\")\n",
    "\n",
    "# Initial model training and evaluation\n",
    "InitialTraining.train_and_evaluate_initial_models(X_train_Le, y_train_Le, X_test_Le, y_test_Le)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best_models_Le = HyperparameterTuning.tune_hyperparameters(X_train_Le, y_train_Le)\n",
    "\n",
    "# Evaluate best models on test set\n",
    "evaluator_Le = ModelEvaluator(best_models_Le)\n",
    "evaluation_results_Le = evaluator_Le.evaluate_models(X_test_Le, y_test_Le)\n",
    "\n",
    "# Train XGBoost model\n",
    "AdvancedModels.train_xgboost(X_train_Le, y_train_Le, X_test_Le, y_test_Le)\n",
    "\n",
    "# Train deep learning model\n",
    "DeepLearningModel.train_deep_learning_model(X_train_Le, y_train_Le, X_test_Le, y_test_Le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui notiamo che il __modello__ che ci restituisce il _risultato migliore_ con i dati attuali sia dopo il OneHot che dopo il Label è il __KNN__ con un'accuratezza rispettivamente di 0.90/0.91 e 0.91/0.93"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
